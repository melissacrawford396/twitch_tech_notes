{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's learn Tensorflow 2.0\n",
    "\n",
    "### Define some terms:\n",
    "* **Tensorflow**: open source library for machine learning tasks. High and low level API's. Eager execution is better for iteration. \n",
    "* **Tensorflow Extended (TFX)**: \n",
    "* **Keras**: (aka, the user friendly Tensorflow) Neural Network Library that is running on top of Tensorflow. Offers high-level API's for building and training models. \n",
    "\n",
    "\n",
    "List of Sites read:\n",
    "- https://analyticsindiamag.com/tensorflow-vs-keras-which-one-should-you-choose/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Super intro Keras/ tensorflow \n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner\n",
    "\n",
    "### Basic Sequential Keras Model\n",
    "- Flatten: Converting a 28x28 image to 1D array\n",
    "- Dense: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "    * units: Dimensionality of the output space\n",
    "    * activation: ReLU \n",
    "- Dropout\n",
    "- Dense\n",
    "\n",
    "\n",
    "##  ReLU - Activation Function\n",
    "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/\n",
    "\n",
    "Rectified Linear Unit activation function. `max(0,x)` pulls value to 0 if negative, passes through positive value).\n",
    "\n",
    "#### Why is it useful\n",
    "\n",
    "\n",
    "## Leaky Relu\n",
    "- vanishing gradient problem\n",
    "\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Backprogation\n",
    "\n",
    "#### Basic Backpropagation without numbers\n",
    "https://www.youtube.com/watch?v=Ilg3gGewQ5U\n",
    "\n",
    "Effects of one MNIST sample: number 2\n",
    "- Nudge values up or down depending on the desired outcome. Output neuron for 2--> we want to increase the likelihood of picking 2, but decrease for all other number's neuron.\n",
    "\n",
    "$$ = \\sigma( w_0*a_0 + w_1*a_1 + ... + w_{n-1}*a_{n-1} + b $$\n",
    "\n",
    "* Increase $b$ (bias)\n",
    "* Increase $w_i$ in proportion to $a_i$: increase the weights for the neurons with larger values. \n",
    "* change $a_i$ in proportion to $w_i$:  (**Is this the part that backpropagates? In layer-2**)\n",
    "\n",
    "#### Layer - 1\n",
    "If you're looking at a 2, certain neurons are going to fire more strongly, so we want those to be strong in recognizing the 2. Increase weights to get 2 selected, decrease weights on selecting all of the other numbers.\n",
    "\n",
    "#### Layer - 2 \n",
    "Recursively pull the values back. We update the weights on layer-1, so we know which direction we want it to go. So when updating the layer-2's weights we go through and get the contribution for each of layer-1. \n",
    "\n",
    "\n",
    "### Stochastic Gradient descent: (batch)\n",
    "Use batches of examples to perform backpropagation instead of using all the examples over and over. \n",
    "<!-- Creating the negative gradient.  -->\n",
    "\n",
    "\n",
    "## Next Time \n",
    "- The Calculus of backpropagation: https://www.youtube.com/watch?v=tIeHLnjs5U8\n",
    "- Activation functions:\n",
    "https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
